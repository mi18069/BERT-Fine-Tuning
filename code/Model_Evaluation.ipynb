{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bcb2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "\n",
    "from transformers import AutoModel\n",
    "from models.ModelRetriever import get_full_classification_model, get_classification_head_model, get_adapters_model, get_lora_model\n",
    "from evaluation.model_evaluator import ModelEvaluator\n",
    "from hf_utils import load_model_from_hf\n",
    "\n",
    "from datasets import load_from_disk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from copy import deepcopy\n",
    "\n",
    "import shutil\n",
    "from transformers import AutoConfig\n",
    "from huggingface_hub import login, HfApi, snapshot_download, upload_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e08f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "BATCH_SIZE = 32\n",
    "NUM_LABELS = 2\n",
    "LABEL_NAMES = ['negative', 'positive']\n",
    "\n",
    "MODEL_NAMES = [\n",
    "    'full_fine_tuning_set_small',\n",
    "    'full_fine_tuning_set_medium',\n",
    "    'full_fine_tuning_set_full',\n",
    "    'head_fine_tuning_set_small',\n",
    "    'head_fine_tuning_set_medium',\n",
    "    'head_fine_tuning_set_full',\n",
    "    'adapters_inner_dim_48_set_small',\n",
    "    'adapters_inner_dim_48_set_medium',\n",
    "    'adapters_inner_dim_48_set_full',\n",
    "    'adapters_inner_dim_96_set_small',\n",
    "    'adapters_inner_dim_96_set_medium',\n",
    "    'adapters_inner_dim_96_set_full',\n",
    "    'lora_r_32_alpha_64_set_small',\n",
    "    'lora_r_32_alpha_64_set_medium',\n",
    "    'lora_r_32_alpha_64_set_full',\n",
    "    'lora_r_64_alpha_32_set_small',\n",
    "    'lora_r_64_alpha_32_set_medium',\n",
    "    'lora_r_64_alpha_32_set_full'\n",
    "]\n",
    "\n",
    "DATASET_PATH = './datasets/test_dataset'\n",
    "SAVE_PATH = './evaluation/evaluation_metrics'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e7e2fd",
   "metadata": {},
   "source": [
    "### Load test dataset\n",
    "\n",
    "This dataset contains of 25_000 test instances, equally splitted in positive and negative, that will be used for evaluating model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load test\n",
    "test_ds = load_from_disk(DATASET_PATH)\n",
    "test_ds.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a678b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = AutoModel.from_pretrained(\"bert-base-uncased\", dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46f1ec5",
   "metadata": {},
   "source": [
    "### Evaluate base model\n",
    "\n",
    "This model will be used as a starting point to which all other fine-tuned models will be measured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9de2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_classification_model = deepcopy(base_model)\n",
    "base_classification_model = get_full_classification_model(base_classification_model)\n",
    "evaluator = ModelEvaluator(base_classification_model, device=DEVICE)\n",
    "evaluator.evaluate(test_loader, num_labels=NUM_LABELS, label_names=LABEL_NAMES)\n",
    "filename = os.path.join(SAVE_PATH, 'base_model.json')\n",
    "evaluator.save_results(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae83dc",
   "metadata": {},
   "source": [
    "### Evaluate fine-tuned models\n",
    "\n",
    "Because fine-tuned models are created by altering structure for the base model, the way they are saved on HF platform is like a structure with it's weights. That's why it's necessary to firstly recreate the exact structure for the desired model and only then set it's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in MODEL_NAMES:\n",
    "    copy_model = deepcopy(base_model)\n",
    "    if model_name.startswith('full'):\n",
    "        adjusted_model = get_full_classification_model(copy_model)\n",
    "    elif model_name.startswith('head'):\n",
    "        adjusted_model = get_classification_head_model(copy_model)\n",
    "    elif model_name.startswith('adapters'):\n",
    "        parts = model_name.split('_')\n",
    "        inner_dim = int(parts[3])\n",
    "        adjusted_model = get_adapters_model(copy_model, inner_dim)\n",
    "    else: \n",
    "        parts = model_name.split('_')\n",
    "        r = int(parts[2])\n",
    "        alpha = int(parts[4])\n",
    "        adjusted_model = get_lora_model(copy_model, r, alpha)\n",
    "        \n",
    "    loaded_model = load_model_from_hf(model_name, adjusted_model)\n",
    "    evaluator = ModelEvaluator(loaded_model, device=DEVICE)\n",
    "    evaluator.evaluate(test_loader, num_labels=NUM_LABELS, label_names=LABEL_NAMES)\n",
    "    filename = os.path.join(SAVE_PATH, f'{model_name}.json')\n",
    "    evaluator.save_results(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
